{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565beba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from model import Encoding_Network\n",
    "from Triplet_Dataset import TripletData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c257e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "865fead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Longer_Encoding_Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Longer_Encoding_Network, self).__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(7, 32, kernel_size=2), nn.ReLU(), nn.Conv2d(32, 64, kernel_size=2), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                 nn.MaxPool2d(2,2))\n",
    "\n",
    "        self.linear = nn.Linear(576, 784)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.linear(x))\n",
    "      \n",
    "        return x\n",
    "    \n",
    "class ScoreNetL3(nn.Module):\n",
    "    def __init__(self, Encoder_Path):\n",
    "        super(ScoreNet, self).__init__()\n",
    "        self.Enc = Longer_Encoding_Network()\n",
    "        self.Enc.load_state_dict(torch.load(Encoder_Path))\n",
    "        \n",
    "        self.linear = nn.Sequential(nn.Linear(1568, 2048), nn.BatchNorm1d(2048), nn.ReLU(), nn.Linear(2048,512),\n",
    "                                    nn.BatchNorm1d(512), nn.ReLU(), nn.Linear(512,1))\n",
    "        \n",
    "    def forward(self,Anchor, Sample):\n",
    "        AnchorVec = self.Enc(Anchor)\n",
    "        SampleVec = self.Enc(Sample)\n",
    "        x = torch.cat((AnchorVec, SampleVec), 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3aa11151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 4758327\n",
      "Test Size: 250439\n"
     ]
    }
   ],
   "source": [
    "dset =  TripletData('training_neighbors.csv', True)\n",
    "trainset, testset = dset.split(.95)\n",
    "\n",
    "trainloader= torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=0 )\n",
    "testloader= torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b92cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,criterion,optimizer,num_epochs,trainloader,testloader):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss=0.0\n",
    "        \n",
    "        for i , (label, anchor, sample) in enumerate(trainloader):\n",
    "            anchor = anchor.to(device)\n",
    "            sample = sample.to(device)\n",
    "            label = label.to(device)\n",
    "            label = label.unsqueeze(1)\n",
    "            label = label.to(torch.float32)\n",
    "            \n",
    "           \n",
    "            #forward prop\n",
    "            \n",
    "            score = model(anchor,sample)\n",
    "            \n",
    "            loss = criterion(score, label)\n",
    "\n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #take step\n",
    "            optimizer.step()\n",
    "            losss= loss.item()\n",
    "            \n",
    "            running_loss+=losss\n",
    "            \n",
    "            \n",
    "           \n",
    "            if i %500==499:\n",
    "                print('[%d,%5d] loss: %.3f' % (epoch+1 , i+1, running_loss/500))\n",
    "                running_loss=0.0\n",
    "            if i % 2000 == 1999: \n",
    "                print(\"Train accuracy: \"+ str(check_accuracy(trainloader, model)*100))\n",
    "                print(\"Test accuracy: \"+ str(check_accuracy(testloader, model)*100))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37fcc4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, full=False):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i , (label, anchor, sample) in enumerate(trainloader):\n",
    "            if i > 200:\n",
    "                model.train()\n",
    "                return num_correct/num_samples\n",
    "                \n",
    "            anchor = anchor.to(device)\n",
    "            sample = sample.to(device)\n",
    "            label = label.to(device)\n",
    "            label = label.unsqueeze(1)\n",
    "            label = label.to(torch.float32)\n",
    "            \n",
    "           \n",
    "            #forward prop\n",
    "            \n",
    "            score = model(anchor,sample)\n",
    "            \n",
    "            \n",
    "            predictions = torch.sigmoid(score) > .5\n",
    "            \n",
    "            \n",
    "            num_correct += (predictions == label).sum()\n",
    "            \n",
    "         \n",
    "            \n",
    "            \n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36639bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScoreNet('./previous_models/LVec2.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37832aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  500] loss: 0.365\n",
      "[1, 1000] loss: 0.358\n",
      "[1, 1500] loss: 0.377\n",
      "[1, 2000] loss: 0.371\n",
      "Train accuracy: tensor(83.7376, device='cuda:0')\n",
      "Test accuracy: tensor(84.2351, device='cuda:0')\n",
      "[1, 2500] loss: 0.366\n",
      "[1, 3000] loss: 0.371\n",
      "[1, 3500] loss: 0.357\n",
      "[1, 4000] loss: 0.368\n",
      "Train accuracy: tensor(84.2662, device='cuda:0')\n",
      "Test accuracy: tensor(83.7065, device='cuda:0')\n",
      "[1, 4500] loss: 0.362\n",
      "[1, 5000] loss: 0.357\n",
      "[1, 5500] loss: 0.366\n",
      "[1, 6000] loss: 0.371\n",
      "Train accuracy: tensor(84.1729, device='cuda:0')\n",
      "Test accuracy: tensor(84.1418, device='cuda:0')\n",
      "[1, 6500] loss: 0.373\n",
      "[1, 7000] loss: 0.373\n",
      "[1, 7500] loss: 0.372\n",
      "[1, 8000] loss: 0.369\n",
      "Train accuracy: tensor(83.8619, device='cuda:0')\n",
      "Test accuracy: tensor(82.4938, device='cuda:0')\n",
      "[1, 8500] loss: 0.364\n",
      "[1, 9000] loss: 0.367\n",
      "[1, 9500] loss: 0.371\n",
      "[1,10000] loss: 0.365\n",
      "Train accuracy: tensor(84.1729, device='cuda:0')\n",
      "Test accuracy: tensor(84.2040, device='cuda:0')\n",
      "[1,10500] loss: 0.375\n",
      "[1,11000] loss: 0.376\n",
      "[1,11500] loss: 0.370\n",
      "[1,12000] loss: 0.364\n",
      "Train accuracy: tensor(83.7065, device='cuda:0')\n",
      "Test accuracy: tensor(84.0796, device='cuda:0')\n",
      "[1,12500] loss: 0.370\n",
      "[1,13000] loss: 0.365\n",
      "[1,13500] loss: 0.364\n",
      "[1,14000] loss: 0.361\n",
      "Train accuracy: tensor(82.9913, device='cuda:0')\n",
      "Test accuracy: tensor(83.3022, device='cuda:0')\n",
      "[1,14500] loss: 0.372\n",
      "[1,15000] loss: 0.368\n",
      "[1,15500] loss: 0.357\n",
      "[1,16000] loss: 0.370\n",
      "Train accuracy: tensor(83.9552, device='cuda:0')\n",
      "Test accuracy: tensor(83.1779, device='cuda:0')\n",
      "[1,16500] loss: 0.364\n",
      "[1,17000] loss: 0.364\n",
      "[1,17500] loss: 0.360\n",
      "[1,18000] loss: 0.360\n",
      "Train accuracy: tensor(83.2711, device='cuda:0')\n",
      "Test accuracy: tensor(83.7065, device='cuda:0')\n",
      "[1,18500] loss: 0.368\n",
      "[1,19000] loss: 0.363\n",
      "[1,19500] loss: 0.356\n",
      "[1,20000] loss: 0.365\n",
      "Train accuracy: tensor(83.2711, device='cuda:0')\n",
      "Test accuracy: tensor(83.2401, device='cuda:0')\n",
      "[1,20500] loss: 0.375\n",
      "[1,21000] loss: 0.373\n",
      "[1,21500] loss: 0.360\n",
      "[1,22000] loss: 0.357\n",
      "Train accuracy: tensor(83.7687, device='cuda:0')\n",
      "Test accuracy: tensor(83.6132, device='cuda:0')\n",
      "[1,22500] loss: 0.364\n",
      "[1,23000] loss: 0.370\n",
      "[1,23500] loss: 0.365\n",
      "[1,24000] loss: 0.359\n",
      "Train accuracy: tensor(85.1057, device='cuda:0')\n",
      "Test accuracy: tensor(84.6393, device='cuda:0')\n",
      "[1,24500] loss: 0.369\n",
      "[1,25000] loss: 0.365\n",
      "[1,25500] loss: 0.359\n",
      "[1,26000] loss: 0.374\n",
      "Train accuracy: tensor(83.4888, device='cuda:0')\n",
      "Test accuracy: tensor(82.3694, device='cuda:0')\n",
      "[1,26500] loss: 0.366\n",
      "[1,27000] loss: 0.377\n",
      "[1,27500] loss: 0.375\n",
      "[1,28000] loss: 0.360\n",
      "Train accuracy: tensor(84.0174, device='cuda:0')\n",
      "Test accuracy: tensor(84.1418, device='cuda:0')\n",
      "[1,28500] loss: 0.363\n",
      "[1,29000] loss: 0.366\n",
      "[1,29500] loss: 0.364\n",
      "[1,30000] loss: 0.367\n",
      "Train accuracy: tensor(83.1779, device='cuda:0')\n",
      "Test accuracy: tensor(83.2711, device='cuda:0')\n",
      "[1,30500] loss: 0.366\n",
      "[1,31000] loss: 0.364\n",
      "[1,31500] loss: 0.370\n",
      "[1,32000] loss: 0.365\n",
      "Train accuracy: tensor(83.7687, device='cuda:0')\n",
      "Test accuracy: tensor(83.1157, device='cuda:0')\n",
      "[1,32500] loss: 0.361\n",
      "[1,33000] loss: 0.375\n",
      "[1,33500] loss: 0.369\n",
      "[1,34000] loss: 0.361\n",
      "Train accuracy: tensor(83.4577, device='cuda:0')\n",
      "Test accuracy: tensor(83.3022, device='cuda:0')\n",
      "[1,34500] loss: 0.364\n",
      "[1,35000] loss: 0.376\n",
      "[1,35500] loss: 0.366\n",
      "[1,36000] loss: 0.368\n",
      "Train accuracy: tensor(83.9552, device='cuda:0')\n",
      "Test accuracy: tensor(82.8669, device='cuda:0')\n",
      "[1,36500] loss: 0.363\n",
      "[1,37000] loss: 0.355\n",
      "[1,37500] loss: 0.372\n",
      "[1,38000] loss: 0.370\n",
      "Train accuracy: tensor(83.1157, device='cuda:0')\n",
      "Test accuracy: tensor(83.8619, device='cuda:0')\n",
      "[1,38500] loss: 0.372\n",
      "[1,39000] loss: 0.355\n",
      "[1,39500] loss: 0.361\n",
      "[1,40000] loss: 0.359\n",
      "Train accuracy: tensor(84.7948, device='cuda:0')\n",
      "Test accuracy: tensor(83.8619, device='cuda:0')\n",
      "[1,40500] loss: 0.364\n",
      "[1,41000] loss: 0.367\n",
      "[1,41500] loss: 0.363\n",
      "[1,42000] loss: 0.363\n",
      "Train accuracy: tensor(82.6492, device='cuda:0')\n",
      "Test accuracy: tensor(83.9863, device='cuda:0')\n",
      "[1,42500] loss: 0.368\n",
      "[1,43000] loss: 0.373\n",
      "[1,43500] loss: 0.358\n",
      "[1,44000] loss: 0.366\n",
      "Train accuracy: tensor(84.7326, device='cuda:0')\n",
      "Test accuracy: tensor(83.0846, device='cuda:0')\n",
      "[1,44500] loss: 0.371\n",
      "[1,45000] loss: 0.364\n",
      "[1,45500] loss: 0.363\n",
      "[1,46000] loss: 0.363\n",
      "Train accuracy: tensor(83.9552, device='cuda:0')\n",
      "Test accuracy: tensor(83.9241, device='cuda:0')\n",
      "[1,46500] loss: 0.369\n",
      "[1,47000] loss: 0.363\n",
      "[1,47500] loss: 0.372\n",
      "[1,48000] loss: 0.364\n",
      "Train accuracy: tensor(85.0435, device='cuda:0')\n",
      "Test accuracy: tensor(82.7114, device='cuda:0')\n",
      "[1,48500] loss: 0.370\n",
      "[1,49000] loss: 0.362\n",
      "[1,49500] loss: 0.356\n",
      "[1,50000] loss: 0.364\n",
      "Train accuracy: tensor(83.4266, device='cuda:0')\n",
      "Test accuracy: tensor(84.3284, device='cuda:0')\n",
      "[1,50500] loss: 0.368\n",
      "[1,51000] loss: 0.355\n",
      "[1,51500] loss: 0.353\n",
      "[1,52000] loss: 0.365\n",
      "Train accuracy: tensor(83.5510, device='cuda:0')\n",
      "Test accuracy: tensor(82.8980, device='cuda:0')\n",
      "[1,52500] loss: 0.365\n",
      "[1,53000] loss: 0.365\n",
      "[1,53500] loss: 0.355\n",
      "[1,54000] loss: 0.369\n",
      "Train accuracy: tensor(84.2662, device='cuda:0')\n",
      "Test accuracy: tensor(83.0224, device='cuda:0')\n",
      "[1,54500] loss: 0.360\n",
      "[1,55000] loss: 0.367\n",
      "[1,55500] loss: 0.361\n",
      "[1,56000] loss: 0.358\n",
      "Train accuracy: tensor(83.7687, device='cuda:0')\n",
      "Test accuracy: tensor(82.8669, device='cuda:0')\n",
      "[1,56500] loss: 0.360\n",
      "[1,57000] loss: 0.364\n",
      "[1,57500] loss: 0.361\n",
      "[1,58000] loss: 0.370\n",
      "Train accuracy: tensor(84.1107, device='cuda:0')\n",
      "Test accuracy: tensor(83.3955, device='cuda:0')\n",
      "[1,58500] loss: 0.364\n",
      "[1,59000] loss: 0.369\n",
      "[1,59500] loss: 0.365\n",
      "[1,60000] loss: 0.363\n",
      "Train accuracy: tensor(83.1157, device='cuda:0')\n",
      "Test accuracy: tensor(83.5510, device='cuda:0')\n",
      "[1,60500] loss: 0.364\n",
      "[1,61000] loss: 0.364\n",
      "[1,61500] loss: 0.360\n",
      "[1,62000] loss: 0.358\n",
      "Train accuracy: tensor(83.7687, device='cuda:0')\n",
      "Test accuracy: tensor(83.7376, device='cuda:0')\n",
      "[1,62500] loss: 0.365\n",
      "[1,63000] loss: 0.363\n",
      "[1,63500] loss: 0.365\n",
      "[1,64000] loss: 0.362\n",
      "Train accuracy: tensor(83.7687, device='cuda:0')\n",
      "Test accuracy: tensor(83.3333, device='cuda:0')\n",
      "[1,64500] loss: 0.359\n",
      "[1,65000] loss: 0.366\n",
      "[1,65500] loss: 0.357\n",
      "[1,66000] loss: 0.353\n",
      "Train accuracy: tensor(83.9241, device='cuda:0')\n",
      "Test accuracy: tensor(84.2973, device='cuda:0')\n",
      "[1,66500] loss: 0.366\n",
      "[1,67000] loss: 0.374\n",
      "[1,67500] loss: 0.359\n",
      "[1,68000] loss: 0.348\n",
      "Train accuracy: tensor(84.9813, device='cuda:0')\n",
      "Test accuracy: tensor(83.7998, device='cuda:0')\n",
      "[1,68500] loss: 0.361\n",
      "[1,69000] loss: 0.371\n",
      "[1,69500] loss: 0.359\n",
      "[1,70000] loss: 0.362\n",
      "Train accuracy: tensor(84.4216, device='cuda:0')\n",
      "Test accuracy: tensor(84.2040, device='cuda:0')\n",
      "[1,70500] loss: 0.367\n",
      "[1,71000] loss: 0.366\n",
      "[1,71500] loss: 0.363\n",
      "[1,72000] loss: 0.365\n",
      "Train accuracy: tensor(84.3595, device='cuda:0')\n",
      "Test accuracy: tensor(83.3955, device='cuda:0')\n",
      "[1,72500] loss: 0.373\n",
      "[1,73000] loss: 0.360\n",
      "[1,73500] loss: 0.364\n",
      "[1,74000] loss: 0.367\n",
      "Train accuracy: tensor(84.9192, device='cuda:0')\n",
      "Test accuracy: tensor(84.5149, device='cuda:0')\n",
      "[1,74500] loss: 0.366\n",
      "[1,75000] loss: 0.380\n",
      "[1,75500] loss: 0.378\n",
      "[1,76000] loss: 0.366\n",
      "Train accuracy: tensor(83.9552, device='cuda:0')\n",
      "Test accuracy: tensor(83.1468, device='cuda:0')\n",
      "[1,76500] loss: 0.365\n",
      "[1,77000] loss: 0.371\n",
      "[1,77500] loss: 0.370\n",
      "[1,78000] loss: 0.366\n",
      "Train accuracy: tensor(84.3284, device='cuda:0')\n",
      "Test accuracy: tensor(84.1107, device='cuda:0')\n",
      "[1,78500] loss: 0.362\n",
      "[1,79000] loss: 0.368\n",
      "[1,79500] loss: 0.361\n",
      "[1,80000] loss: 0.383\n",
      "Train accuracy: tensor(84.2973, device='cuda:0')\n",
      "Test accuracy: tensor(82.1517, device='cuda:0')\n",
      "[1,80500] loss: 0.366\n",
      "[1,81000] loss: 0.367\n",
      "[1,81500] loss: 0.361\n",
      "[1,82000] loss: 0.361\n",
      "Train accuracy: tensor(83.8619, device='cuda:0')\n",
      "Test accuracy: tensor(84.5149, device='cuda:0')\n",
      "[1,82500] loss: 0.372\n",
      "[1,83000] loss: 0.364\n",
      "[1,83500] loss: 0.362\n",
      "[1,84000] loss: 0.366\n",
      "Train accuracy: tensor(85.0124, device='cuda:0')\n",
      "Test accuracy: tensor(84.6393, device='cuda:0')\n",
      "[1,84500] loss: 0.361\n",
      "[1,85000] loss: 0.370\n",
      "[1,85500] loss: 0.370\n",
      "[1,86000] loss: 0.360\n",
      "Train accuracy: tensor(83.6132, device='cuda:0')\n",
      "Test accuracy: tensor(84.3284, device='cuda:0')\n",
      "[1,86500] loss: 0.362\n",
      "[1,87000] loss: 0.368\n",
      "[1,87500] loss: 0.361\n",
      "[1,88000] loss: 0.362\n",
      "Train accuracy: tensor(83.7998, device='cuda:0')\n",
      "Test accuracy: tensor(84.2973, device='cuda:0')\n",
      "[1,88500] loss: 0.375\n",
      "[1,89000] loss: 0.359\n",
      "[1,89500] loss: 0.373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,90000] loss: 0.364\n",
      "Train accuracy: tensor(83.0846, device='cuda:0')\n",
      "Test accuracy: tensor(83.5510, device='cuda:0')\n",
      "[1,90500] loss: 0.372\n",
      "[1,91000] loss: 0.367\n",
      "[1,91500] loss: 0.364\n",
      "[1,92000] loss: 0.359\n",
      "Train accuracy: tensor(83.9863, device='cuda:0')\n",
      "Test accuracy: tensor(83.1157, device='cuda:0')\n",
      "[1,92500] loss: 0.360\n",
      "[1,93000] loss: 0.363\n",
      "[1,93500] loss: 0.371\n",
      "[1,94000] loss: 0.370\n",
      "Train accuracy: tensor(83.6443, device='cuda:0')\n",
      "Test accuracy: tensor(83.7687, device='cuda:0')\n",
      "[1,94500] loss: 0.361\n",
      "[1,95000] loss: 0.364\n",
      "[1,95500] loss: 0.365\n",
      "[1,96000] loss: 0.369\n",
      "Train accuracy: tensor(82.9913, device='cuda:0')\n",
      "Test accuracy: tensor(83.6443, device='cuda:0')\n",
      "[1,96500] loss: 0.364\n",
      "[1,97000] loss: 0.367\n",
      "[1,97500] loss: 0.366\n",
      "[1,98000] loss: 0.360\n",
      "Train accuracy: tensor(83.4577, device='cuda:0')\n",
      "Test accuracy: tensor(82.8047, device='cuda:0')\n",
      "[1,98500] loss: 0.360\n",
      "[1,99000] loss: 0.372\n",
      "[1,99500] loss: 0.369\n",
      "[1,100000] loss: 0.362\n",
      "Train accuracy: tensor(84.7326, device='cuda:0')\n",
      "Test accuracy: tensor(83.7998, device='cuda:0')\n",
      "[1,100500] loss: 0.355\n",
      "[1,101000] loss: 0.366\n",
      "[1,101500] loss: 0.369\n",
      "[1,102000] loss: 0.364\n",
      "Train accuracy: tensor(83.8930, device='cuda:0')\n",
      "Test accuracy: tensor(83.4577, device='cuda:0')\n",
      "[1,102500] loss: 0.362\n",
      "[1,103000] loss: 0.375\n",
      "[1,103500] loss: 0.371\n",
      "[1,104000] loss: 0.367\n",
      "Train accuracy: tensor(83.8930, device='cuda:0')\n",
      "Test accuracy: tensor(83.3022, device='cuda:0')\n",
      "[1,104500] loss: 0.368\n",
      "[1,105000] loss: 0.356\n",
      "[1,105500] loss: 0.359\n",
      "[1,106000] loss: 0.367\n",
      "Train accuracy: tensor(83.1157, device='cuda:0')\n",
      "Test accuracy: tensor(84.9192, device='cuda:0')\n",
      "[1,106500] loss: 0.356\n",
      "[1,107000] loss: 0.376\n",
      "[1,107500] loss: 0.365\n",
      "[1,108000] loss: 0.358\n",
      "Train accuracy: tensor(84.6082, device='cuda:0')\n",
      "Test accuracy: tensor(84.0174, device='cuda:0')\n",
      "[1,108500] loss: 0.369\n",
      "[1,109000] loss: 0.376\n",
      "[1,109500] loss: 0.372\n",
      "[1,110000] loss: 0.366\n",
      "Train accuracy: tensor(84.7326, device='cuda:0')\n",
      "Test accuracy: tensor(82.7114, device='cuda:0')\n",
      "[1,110500] loss: 0.366\n",
      "[1,111000] loss: 0.368\n",
      "[1,111500] loss: 0.362\n",
      "[1,112000] loss: 0.363\n",
      "Train accuracy: tensor(83.4888, device='cuda:0')\n",
      "Test accuracy: tensor(82.4938, device='cuda:0')\n",
      "[1,112500] loss: 0.358\n",
      "[1,113000] loss: 0.354\n",
      "[1,113500] loss: 0.358\n",
      "[1,114000] loss: 0.374\n",
      "Train accuracy: tensor(83.3955, device='cuda:0')\n",
      "Test accuracy: tensor(83.5199, device='cuda:0')\n",
      "[1,114500] loss: 0.364\n",
      "[1,115000] loss: 0.367\n",
      "[1,115500] loss: 0.358\n",
      "[1,116000] loss: 0.366\n",
      "Train accuracy: tensor(83.9863, device='cuda:0')\n",
      "Test accuracy: tensor(83.5199, device='cuda:0')\n",
      "[1,116500] loss: 0.365\n",
      "[1,117000] loss: 0.365\n",
      "[1,117500] loss: 0.370\n",
      "[1,118000] loss: 0.361\n",
      "Train accuracy: tensor(82.3383, device='cuda:0')\n",
      "Test accuracy: tensor(83.9552, device='cuda:0')\n",
      "[1,118500] loss: 0.363\n",
      "[1,119000] loss: 0.369\n",
      "[1,119500] loss: 0.362\n",
      "[1,120000] loss: 0.359\n",
      "Train accuracy: tensor(82.8047, device='cuda:0')\n",
      "Test accuracy: tensor(83.5821, device='cuda:0')\n",
      "[1,120500] loss: 0.350\n",
      "[1,121000] loss: 0.360\n",
      "[1,121500] loss: 0.358\n",
      "[1,122000] loss: 0.357\n",
      "Train accuracy: tensor(82.8047, device='cuda:0')\n",
      "Test accuracy: tensor(84.3905, device='cuda:0')\n",
      "[1,122500] loss: 0.358\n",
      "[1,123000] loss: 0.359\n",
      "[1,123500] loss: 0.362\n",
      "[1,124000] loss: 0.361\n",
      "Train accuracy: tensor(83.1157, device='cuda:0')\n",
      "Test accuracy: tensor(84.2973, device='cuda:0')\n",
      "[1,124500] loss: 0.363\n",
      "[1,125000] loss: 0.361\n",
      "[1,125500] loss: 0.362\n",
      "[1,126000] loss: 0.357\n",
      "Train accuracy: tensor(83.3022, device='cuda:0')\n",
      "Test accuracy: tensor(83.7376, device='cuda:0')\n",
      "[1,126500] loss: 0.364\n",
      "[1,127000] loss: 0.366\n",
      "[1,127500] loss: 0.370\n",
      "[1,128000] loss: 0.361\n",
      "Train accuracy: tensor(83.4577, device='cuda:0')\n",
      "Test accuracy: tensor(83.7998, device='cuda:0')\n",
      "[1,128500] loss: 0.365\n",
      "[1,129000] loss: 0.372\n",
      "[1,129500] loss: 0.362\n",
      "[1,130000] loss: 0.366\n",
      "Train accuracy: tensor(84.0485, device='cuda:0')\n",
      "Test accuracy: tensor(84.8570, device='cuda:0')\n",
      "[1,130500] loss: 0.366\n",
      "[1,131000] loss: 0.358\n",
      "[1,131500] loss: 0.364\n",
      "[1,132000] loss: 0.363\n",
      "Train accuracy: tensor(83.4577, device='cuda:0')\n",
      "Test accuracy: tensor(83.6132, device='cuda:0')\n",
      "[1,132500] loss: 0.364\n",
      "[1,133000] loss: 0.359\n",
      "[1,133500] loss: 0.361\n",
      "[1,134000] loss: 0.344\n",
      "Train accuracy: tensor(84.1418, device='cuda:0')\n",
      "Test accuracy: tensor(84.4216, device='cuda:0')\n",
      "[1,134500] loss: 0.362\n",
      "[1,135000] loss: 0.356\n",
      "[1,135500] loss: 0.369\n",
      "[1,136000] loss: 0.360\n",
      "Train accuracy: tensor(83.8308, device='cuda:0')\n",
      "Test accuracy: tensor(83.8619, device='cuda:0')\n",
      "[1,136500] loss: 0.358\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "learning_rate = .5e-3\n",
    "num_epochs = 10\n",
    "criterion3 = nn.BCEWithLogitsLoss()\n",
    "optimizer3=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "#optimizer3 = optim.SGD(my_model.parameters(),lr=learning_rate,momentum=.9)\n",
    "num_epochs=15\n",
    "train(model,criterion3,optimizer3,num_epochs,trainloader,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71ee59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './previous_models/ScoreNetL3-83.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64113ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''./previous_models/LVec1.pth\n",
    "\n",
    "./previous_models/ScoreNet1.pth\n",
    "class ScoreNet(nn.Module):\n",
    "    def __init__(self, Encoder_Path):\n",
    "        super(ScoreNet, self).__init__()\n",
    "        self.Enc = Encoding_Network()\n",
    "        self.Enc.load_state_dict(torch.load(Encoder_Path))\n",
    "        \n",
    "        self.linear = nn.Sequential(nn.Linear(512, 1))\n",
    "        \n",
    "    def forward(self,Anchor, Sample):\n",
    "        AnchorVec = self.Enc(Anchor)\n",
    "        SampleVec = self.Enc(Sample)\n",
    "        x = torch.cat((AnchorVec, SampleVec), 1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "./previous_models/ScoreNet2.pth        \n",
    "class ScoreNet(nn.Module):\n",
    "    def __init__(self, Encoder_Path):\n",
    "        super(ScoreNet, self).__init__()\n",
    "        self.Enc = Encoding_Network()\n",
    "        self.Enc.load_state_dict(torch.load(Encoder_Path))\n",
    "        \n",
    "        self.linear = nn.Sequential(nn.Linear(512, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Linear(128,1))\n",
    "        \n",
    "    def forward(self,Anchor, Sample):\n",
    "        AnchorVec = self.Enc(Anchor)\n",
    "        SampleVec = self.Enc(Sample)\n",
    "        x = torch.cat((AnchorVec, SampleVec), 1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "        \n",
    "./previous_models/ScoreNet3.pth        \n",
    "class ScoreNet(nn.Module):\n",
    "    def __init__(self, Encoder_Path):\n",
    "        super(ScoreNet, self).__init__()\n",
    "        self.Enc = Encoding_Network()\n",
    "        self.Enc.load_state_dict(torch.load(Encoder_Path))\n",
    "        \n",
    "        self.linear = nn.Sequential(nn.Linear(512, 1024), nn.BatchNorm1d(1024), nn.ReLU(), nn.Linear(1024,512),\n",
    "                                    nn.BatchNorm1d(512), nn.ReLU(), nn.Linear(512,1) )\n",
    "        \n",
    "    def forward(self,Anchor, Sample):\n",
    "        AnchorVec = self.Enc(Anchor)\n",
    "        SampleVec = self.Enc(Sample)\n",
    "        x = torch.cat((AnchorVec, SampleVec), 1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "        \n",
    "'./previous_models/ScoreNet4.pth'   78% .45      \n",
    "class ScoreNet(nn.Module):#must be paird w long vector\n",
    "    def __init__(self, Encoder_Path):\n",
    "        super(ScoreNet, self).__init__()\n",
    "        self.Enc = Longer_Encoding_Network()\n",
    "        self.Enc.load_state_dict(torch.load(Encoder_Path))\n",
    "        \n",
    "        self.linear = nn.Sequential(nn.Linear(1568, 3012), nn.BatchNorm1d(3012), nn.ReLU(), nn.Linear(3012,512), nn.BatchNorm1d(512),nn.ReLU(), nn.Linear(512,1) )\n",
    "        \n",
    "    def forward(self,Anchor, Sample):\n",
    "        AnchorVec = self.Enc(Anchor)\n",
    "        SampleVec = self.Enc(Sample)\n",
    "        x = torch.cat((AnchorVec, SampleVec), 1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chess_Enviorment",
   "language": "python",
   "name": "chess_enviorment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
