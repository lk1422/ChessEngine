{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b7e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from model import Encoding_Network\n",
    "from Triplet_Dataset import TripletData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106d4335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14f6bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Longer_Encoding_Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Longer_Encoding_Network, self).__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(7, 32, kernel_size=2), nn.ReLU(), nn.Conv2d(32, 64, kernel_size=2), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                 nn.MaxPool2d(2,2))\n",
    "\n",
    "        self.linear = nn.Linear(576, 784)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.linear(x))\n",
    "      \n",
    "        return x\n",
    "    \n",
    "class ScoreNetL2(nn.Module):#\n",
    "    def __init__(self, Encoder_Path):\n",
    "        super(ScoreNet, self).__init__()\n",
    "        self.Enc = Longer_Encoding_Network()\n",
    "        self.Enc.load_state_dict(torch.load(Encoder_Path))\n",
    "        \n",
    "        self.linear = nn.Sequential(nn.Linear(1568, 1024), nn.BatchNorm1d(1024), nn.ReLU(), nn.Linear(1024,1))\n",
    "        \n",
    "    def forward(self,Anchor, Sample):\n",
    "        AnchorVec = self.Enc(Anchor)\n",
    "        SampleVec = self.Enc(Sample)\n",
    "        x = torch.cat((AnchorVec, SampleVec), 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7b6cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 4758327\n",
      "Test Size: 250439\n"
     ]
    }
   ],
   "source": [
    "dset =  TripletData('training_neighbors.csv', True)\n",
    "trainset, testset = dset.split(.95)\n",
    "\n",
    "trainloader= torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=0 )\n",
    "testloader= torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f71a261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,criterion,optimizer,num_epochs,trainloader,testloader):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss=0.0\n",
    "        \n",
    "        for i , (label, anchor, sample) in enumerate(trainloader):\n",
    "            anchor = anchor.to(device)\n",
    "            sample = sample.to(device)\n",
    "            label = label.to(device)\n",
    "            label = label.unsqueeze(1)\n",
    "            label = label.to(torch.float32)\n",
    "            \n",
    "           \n",
    "            #forward prop\n",
    "            \n",
    "            score = model(anchor,sample)\n",
    "            \n",
    "            loss = criterion(score, label)\n",
    "\n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #take step\n",
    "            optimizer.step()\n",
    "            losss= loss.item()\n",
    "            \n",
    "            running_loss+=losss\n",
    "            \n",
    "            \n",
    "           \n",
    "            if i %500==499:\n",
    "                print('[%d,%5d] loss: %.3f' % (epoch+1 , i+1, running_loss/500))\n",
    "                running_loss=0.0\n",
    "            if i % 2000 == 1999: \n",
    "                print(\"Train accuracy: \"+ str(check_accuracy(trainloader, model)*100))\n",
    "                print(\"Test accuracy: \"+ str(check_accuracy(testloader, model)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7804605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, full=False):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i , (label, anchor, sample) in enumerate(trainloader):\n",
    "            if i > 200:\n",
    "                model.train()\n",
    "                return num_correct/num_samples\n",
    "                \n",
    "            anchor = anchor.to(device)\n",
    "            sample = sample.to(device)\n",
    "            label = label.to(device)\n",
    "            label = label.unsqueeze(1)\n",
    "            label = label.to(torch.float32)\n",
    "            \n",
    "           \n",
    "            #forward prop\n",
    "            \n",
    "            score = model(anchor,sample)\n",
    "            \n",
    "            \n",
    "            predictions = torch.sigmoid(score) > .5\n",
    "            \n",
    "            \n",
    "            num_correct += (predictions == label).sum()\n",
    "            \n",
    "         \n",
    "            \n",
    "            \n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "375eb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScoreNet('./previous_models/LVec2.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f30cffe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  500] loss: 0.346\n",
      "[1, 1000] loss: 0.357\n",
      "[1, 1500] loss: 0.343\n",
      "[1, 2000] loss: 0.358\n",
      "Train accuracy: tensor(84.4216, device='cuda:0')\n",
      "Test accuracy: tensor(83.6132, device='cuda:0')\n",
      "[1, 2500] loss: 0.391\n",
      "[1, 3000] loss: 0.387\n",
      "[1, 3500] loss: 0.380\n",
      "[1, 4000] loss: 0.372\n",
      "Train accuracy: tensor(83.1468, device='cuda:0')\n",
      "Test accuracy: tensor(82.4627, device='cuda:0')\n",
      "[1, 4500] loss: 0.378\n",
      "[1, 5000] loss: 0.384\n",
      "[1, 5500] loss: 0.374\n",
      "[1, 6000] loss: 0.384\n",
      "Train accuracy: tensor(83.5199, device='cuda:0')\n",
      "Test accuracy: tensor(84.1729, device='cuda:0')\n",
      "[1, 6500] loss: 0.372\n",
      "[1, 7000] loss: 0.376\n",
      "[1, 7500] loss: 0.381\n",
      "[1, 8000] loss: 0.381\n",
      "Train accuracy: tensor(83.9552, device='cuda:0')\n",
      "Test accuracy: tensor(83.8619, device='cuda:0')\n",
      "[1, 8500] loss: 0.377\n",
      "[1, 9000] loss: 0.382\n",
      "[1, 9500] loss: 0.386\n",
      "[1,10000] loss: 0.385\n",
      "Train accuracy: tensor(84.0796, device='cuda:0')\n",
      "Test accuracy: tensor(83.8308, device='cuda:0')\n",
      "[1,10500] loss: 0.378\n",
      "[1,11000] loss: 0.380\n",
      "[1,11500] loss: 0.392\n",
      "[1,12000] loss: 0.371\n",
      "Train accuracy: tensor(84.3595, device='cuda:0')\n",
      "Test accuracy: tensor(83.9552, device='cuda:0')\n",
      "[1,12500] loss: 0.378\n",
      "[1,13000] loss: 0.375\n",
      "[1,13500] loss: 0.375\n",
      "[1,14000] loss: 0.373\n",
      "Train accuracy: tensor(84.2351, device='cuda:0')\n",
      "Test accuracy: tensor(84.7637, device='cuda:0')\n",
      "[1,14500] loss: 0.386\n",
      "[1,15000] loss: 0.371\n",
      "[1,15500] loss: 0.378\n",
      "[1,16000] loss: 0.379\n",
      "Train accuracy: tensor(83.7065, device='cuda:0')\n",
      "Test accuracy: tensor(84.9192, device='cuda:0')\n",
      "[1,16500] loss: 0.376\n",
      "[1,17000] loss: 0.383\n",
      "[1,17500] loss: 0.368\n",
      "[1,18000] loss: 0.375\n",
      "Train accuracy: tensor(84.0174, device='cuda:0')\n",
      "Test accuracy: tensor(82.1828, device='cuda:0')\n",
      "[1,18500] loss: 0.378\n",
      "[1,19000] loss: 0.370\n",
      "[1,19500] loss: 0.381\n",
      "[1,20000] loss: 0.382\n",
      "Train accuracy: tensor(83.5199, device='cuda:0')\n",
      "Test accuracy: tensor(83.7065, device='cuda:0')\n",
      "[1,20500] loss: 0.377\n",
      "[1,21000] loss: 0.376\n",
      "[1,21500] loss: 0.388\n",
      "[1,22000] loss: 0.371\n",
      "Train accuracy: tensor(83.8930, device='cuda:0')\n",
      "Test accuracy: tensor(83.5199, device='cuda:0')\n",
      "[1,22500] loss: 0.376\n",
      "[1,23000] loss: 0.368\n",
      "[1,23500] loss: 0.388\n",
      "[1,24000] loss: 0.374\n",
      "Train accuracy: tensor(83.6132, device='cuda:0')\n",
      "Test accuracy: tensor(82.5560, device='cuda:0')\n",
      "[1,24500] loss: 0.377\n",
      "[1,25000] loss: 0.375\n",
      "[1,25500] loss: 0.385\n",
      "[1,26000] loss: 0.376\n",
      "Train accuracy: tensor(83.4577, device='cuda:0')\n",
      "Test accuracy: tensor(83.9552, device='cuda:0')\n",
      "[1,26500] loss: 0.385\n",
      "[1,27000] loss: 0.375\n",
      "[1,27500] loss: 0.382\n",
      "[1,28000] loss: 0.374\n",
      "Train accuracy: tensor(83.1779, device='cuda:0')\n",
      "Test accuracy: tensor(83.7998, device='cuda:0')\n",
      "[1,28500] loss: 0.377\n",
      "[1,29000] loss: 0.385\n",
      "[1,29500] loss: 0.378\n",
      "[1,30000] loss: 0.390\n",
      "Train accuracy: tensor(84.8881, device='cuda:0')\n",
      "Test accuracy: tensor(84.1418, device='cuda:0')\n",
      "[1,30500] loss: 0.375\n",
      "[1,31000] loss: 0.366\n",
      "[1,31500] loss: 0.374\n",
      "[1,32000] loss: 0.384\n",
      "Train accuracy: tensor(83.9241, device='cuda:0')\n",
      "Test accuracy: tensor(82.9913, device='cuda:0')\n",
      "[1,32500] loss: 0.375\n",
      "[1,33000] loss: 0.372\n",
      "[1,33500] loss: 0.384\n",
      "[1,34000] loss: 0.377\n",
      "Train accuracy: tensor(83.3644, device='cuda:0')\n",
      "Test accuracy: tensor(83.2401, device='cuda:0')\n",
      "[1,34500] loss: 0.387\n",
      "[1,35000] loss: 0.378\n",
      "[1,35500] loss: 0.383\n",
      "[1,36000] loss: 0.382\n",
      "Train accuracy: tensor(82.6182, device='cuda:0')\n",
      "Test accuracy: tensor(84.5149, device='cuda:0')\n",
      "[1,36500] loss: 0.377\n",
      "[1,37000] loss: 0.370\n",
      "[1,37500] loss: 0.383\n",
      "[1,38000] loss: 0.378\n",
      "Train accuracy: tensor(83.3022, device='cuda:0')\n",
      "Test accuracy: tensor(81.8408, device='cuda:0')\n",
      "[1,38500] loss: 0.379\n",
      "[1,39000] loss: 0.382\n",
      "[1,39500] loss: 0.374\n",
      "[1,40000] loss: 0.370\n",
      "Train accuracy: tensor(83.3333, device='cuda:0')\n",
      "Test accuracy: tensor(82.3383, device='cuda:0')\n",
      "[1,40500] loss: 0.375\n",
      "[1,41000] loss: 0.377\n",
      "[1,41500] loss: 0.384\n",
      "[1,42000] loss: 0.381\n",
      "Train accuracy: tensor(83.9552, device='cuda:0')\n",
      "Test accuracy: tensor(84.1418, device='cuda:0')\n",
      "[1,42500] loss: 0.384\n",
      "[1,43000] loss: 0.375\n",
      "[1,43500] loss: 0.368\n",
      "[1,44000] loss: 0.376\n",
      "Train accuracy: tensor(83.1468, device='cuda:0')\n",
      "Test accuracy: tensor(84.3595, device='cuda:0')\n",
      "[1,44500] loss: 0.373\n",
      "[1,45000] loss: 0.377\n",
      "[1,45500] loss: 0.385\n",
      "[1,46000] loss: 0.376\n",
      "Train accuracy: tensor(83.2401, device='cuda:0')\n",
      "Test accuracy: tensor(83.9863, device='cuda:0')\n",
      "[1,46500] loss: 0.372\n",
      "[1,47000] loss: 0.372\n",
      "[1,47500] loss: 0.384\n",
      "[1,48000] loss: 0.382\n",
      "Train accuracy: tensor(84.4216, device='cuda:0')\n",
      "Test accuracy: tensor(84.0796, device='cuda:0')\n",
      "[1,48500] loss: 0.382\n",
      "[1,49000] loss: 0.374\n",
      "[1,49500] loss: 0.380\n",
      "[1,50000] loss: 0.387\n",
      "Train accuracy: tensor(83.0846, device='cuda:0')\n",
      "Test accuracy: tensor(83.1157, device='cuda:0')\n",
      "[1,50500] loss: 0.376\n",
      "[1,51000] loss: 0.380\n",
      "[1,51500] loss: 0.373\n",
      "[1,52000] loss: 0.380\n",
      "Train accuracy: tensor(83.4577, device='cuda:0')\n",
      "Test accuracy: tensor(83.2711, device='cuda:0')\n",
      "[1,52500] loss: 0.387\n",
      "[1,53000] loss: 0.373\n",
      "[1,53500] loss: 0.392\n",
      "[1,54000] loss: 0.375\n",
      "Train accuracy: tensor(83.7376, device='cuda:0')\n",
      "Test accuracy: tensor(83.4266, device='cuda:0')\n",
      "[1,54500] loss: 0.386\n",
      "[1,55000] loss: 0.378\n",
      "[1,55500] loss: 0.393\n",
      "[1,56000] loss: 0.374\n",
      "Train accuracy: tensor(83.6443, device='cuda:0')\n",
      "Test accuracy: tensor(83.9241, device='cuda:0')\n",
      "[1,56500] loss: 0.378\n",
      "[1,57000] loss: 0.382\n",
      "[1,57500] loss: 0.376\n",
      "[1,58000] loss: 0.386\n",
      "Train accuracy: tensor(84.3905, device='cuda:0')\n",
      "Test accuracy: tensor(83.9863, device='cuda:0')\n",
      "[1,58500] loss: 0.384\n",
      "[1,59000] loss: 0.374\n",
      "[1,59500] loss: 0.370\n",
      "[1,60000] loss: 0.386\n",
      "Train accuracy: tensor(85.0435, device='cuda:0')\n",
      "Test accuracy: tensor(83.9863, device='cuda:0')\n",
      "[1,60500] loss: 0.381\n",
      "[1,61000] loss: 0.370\n",
      "[1,61500] loss: 0.378\n",
      "[1,62000] loss: 0.381\n",
      "Train accuracy: tensor(83.3644, device='cuda:0')\n",
      "Test accuracy: tensor(83.9241, device='cuda:0')\n",
      "[1,62500] loss: 0.376\n",
      "[1,63000] loss: 0.374\n",
      "[1,63500] loss: 0.381\n",
      "[1,64000] loss: 0.374\n",
      "Train accuracy: tensor(82.1206, device='cuda:0')\n",
      "Test accuracy: tensor(81.6231, device='cuda:0')\n",
      "[1,64500] loss: 0.375\n",
      "[1,65000] loss: 0.381\n",
      "[1,65500] loss: 0.385\n",
      "[1,66000] loss: 0.374\n",
      "Train accuracy: tensor(84.4838, device='cuda:0')\n",
      "Test accuracy: tensor(83.5821, device='cuda:0')\n",
      "[1,66500] loss: 0.389\n",
      "[1,67000] loss: 0.381\n",
      "[1,67500] loss: 0.373\n",
      "[1,68000] loss: 0.376\n",
      "Train accuracy: tensor(83.1779, device='cuda:0')\n",
      "Test accuracy: tensor(83.3022, device='cuda:0')\n",
      "[1,68500] loss: 0.383\n",
      "[1,69000] loss: 0.383\n",
      "[1,69500] loss: 0.373\n",
      "[1,70000] loss: 0.377\n",
      "Train accuracy: tensor(84.2351, device='cuda:0')\n",
      "Test accuracy: tensor(82.7114, device='cuda:0')\n",
      "[1,70500] loss: 0.375\n",
      "[1,71000] loss: 0.374\n",
      "[1,71500] loss: 0.378\n",
      "[1,72000] loss: 0.373\n",
      "Train accuracy: tensor(84.2973, device='cuda:0')\n",
      "Test accuracy: tensor(82.2139, device='cuda:0')\n",
      "[1,72500] loss: 0.380\n",
      "[1,73000] loss: 0.373\n",
      "[1,73500] loss: 0.383\n",
      "[1,74000] loss: 0.388\n",
      "Train accuracy: tensor(83.3333, device='cuda:0')\n",
      "Test accuracy: tensor(84.2973, device='cuda:0')\n",
      "[1,74500] loss: 0.387\n",
      "[1,75000] loss: 0.377\n",
      "[1,75500] loss: 0.382\n",
      "[1,76000] loss: 0.369\n",
      "Train accuracy: tensor(83.7376, device='cuda:0')\n",
      "Test accuracy: tensor(83.9552, device='cuda:0')\n",
      "[1,76500] loss: 0.385\n",
      "[1,77000] loss: 0.384\n",
      "[1,77500] loss: 0.375\n",
      "[1,78000] loss: 0.377\n",
      "Train accuracy: tensor(83.3333, device='cuda:0')\n",
      "Test accuracy: tensor(83.4577, device='cuda:0')\n",
      "[1,78500] loss: 0.383\n",
      "[1,79000] loss: 0.384\n",
      "[1,79500] loss: 0.370\n",
      "[1,80000] loss: 0.385\n",
      "Train accuracy: tensor(83.4888, device='cuda:0')\n",
      "Test accuracy: tensor(83.9863, device='cuda:0')\n",
      "[1,80500] loss: 0.377\n",
      "[1,81000] loss: 0.386\n",
      "[1,81500] loss: 0.376\n",
      "[1,82000] loss: 0.362\n",
      "Train accuracy: tensor(83.7065, device='cuda:0')\n",
      "Test accuracy: tensor(84.4216, device='cuda:0')\n",
      "[1,82500] loss: 0.382\n",
      "[1,83000] loss: 0.385\n",
      "[1,83500] loss: 0.379\n",
      "[1,84000] loss: 0.373\n",
      "Train accuracy: tensor(83.5199, device='cuda:0')\n",
      "Test accuracy: tensor(82.2450, device='cuda:0')\n",
      "[1,84500] loss: 0.375\n",
      "[1,85000] loss: 0.387\n",
      "[1,85500] loss: 0.383\n",
      "[1,86000] loss: 0.387\n",
      "Train accuracy: tensor(83.5199, device='cuda:0')\n",
      "Test accuracy: tensor(83.0224, device='cuda:0')\n",
      "[1,86500] loss: 0.377\n",
      "[1,87000] loss: 0.375\n",
      "[1,87500] loss: 0.375\n",
      "[1,88000] loss: 0.378\n",
      "Train accuracy: tensor(83.3644, device='cuda:0')\n",
      "Test accuracy: tensor(84.0174, device='cuda:0')\n",
      "[1,88500] loss: 0.383\n",
      "[1,89000] loss: 0.385\n",
      "[1,89500] loss: 0.368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,90000] loss: 0.373\n",
      "Train accuracy: tensor(82.6492, device='cuda:0')\n",
      "Test accuracy: tensor(83.9241, device='cuda:0')\n",
      "[1,90500] loss: 0.378\n",
      "[1,91000] loss: 0.381\n",
      "[1,91500] loss: 0.376\n",
      "[1,92000] loss: 0.385\n",
      "Train accuracy: tensor(82.6803, device='cuda:0')\n",
      "Test accuracy: tensor(82.4627, device='cuda:0')\n",
      "[1,92500] loss: 0.373\n",
      "[1,93000] loss: 0.375\n",
      "[1,93500] loss: 0.382\n",
      "[1,94000] loss: 0.376\n",
      "Train accuracy: tensor(84.0174, device='cuda:0')\n",
      "Test accuracy: tensor(83.0224, device='cuda:0')\n",
      "[1,94500] loss: 0.377\n",
      "[1,95000] loss: 0.383\n",
      "[1,95500] loss: 0.367\n",
      "[1,96000] loss: 0.378\n",
      "Train accuracy: tensor(83.6754, device='cuda:0')\n",
      "Test accuracy: tensor(82.9602, device='cuda:0')\n",
      "[1,96500] loss: 0.378\n",
      "[1,97000] loss: 0.364\n",
      "[1,97500] loss: 0.381\n",
      "[1,98000] loss: 0.383\n",
      "Train accuracy: tensor(83.8308, device='cuda:0')\n",
      "Test accuracy: tensor(83.6132, device='cuda:0')\n",
      "[1,98500] loss: 0.387\n",
      "[1,99000] loss: 0.384\n",
      "[1,99500] loss: 0.368\n",
      "[1,100000] loss: 0.372\n",
      "Train accuracy: tensor(84.5460, device='cuda:0')\n",
      "Test accuracy: tensor(84.1418, device='cuda:0')\n",
      "[1,100500] loss: 0.366\n",
      "[1,101000] loss: 0.376\n",
      "[1,101500] loss: 0.387\n",
      "[1,102000] loss: 0.383\n",
      "Train accuracy: tensor(82.1828, device='cuda:0')\n",
      "Test accuracy: tensor(83.6754, device='cuda:0')\n",
      "[1,102500] loss: 0.372\n",
      "[1,103000] loss: 0.380\n",
      "[1,103500] loss: 0.370\n",
      "[1,104000] loss: 0.385\n",
      "Train accuracy: tensor(84.2973, device='cuda:0')\n",
      "Test accuracy: tensor(83.5510, device='cuda:0')\n",
      "[1,104500] loss: 0.378\n",
      "[1,105000] loss: 0.377\n",
      "[1,105500] loss: 0.385\n",
      "[1,106000] loss: 0.380\n",
      "Train accuracy: tensor(83.7065, device='cuda:0')\n",
      "Test accuracy: tensor(84.0796, device='cuda:0')\n",
      "[1,106500] loss: 0.375\n",
      "[1,107000] loss: 0.383\n",
      "[1,107500] loss: 0.378\n",
      "[1,108000] loss: 0.382\n",
      "Train accuracy: tensor(83.5199, device='cuda:0')\n",
      "Test accuracy: tensor(83.5821, device='cuda:0')\n",
      "[1,108500] loss: 0.376\n",
      "[1,109000] loss: 0.377\n",
      "[1,109500] loss: 0.380\n",
      "[1,110000] loss: 0.377\n",
      "Train accuracy: tensor(83.5199, device='cuda:0')\n",
      "Test accuracy: tensor(84.0796, device='cuda:0')\n",
      "[1,110500] loss: 0.378\n",
      "[1,111000] loss: 0.373\n",
      "[1,111500] loss: 0.375\n",
      "[1,112000] loss: 0.379\n",
      "Train accuracy: tensor(83.5510, device='cuda:0')\n",
      "Test accuracy: tensor(84.4527, device='cuda:0')\n",
      "[1,112500] loss: 0.385\n",
      "[1,113000] loss: 0.383\n",
      "[1,113500] loss: 0.378\n",
      "[1,114000] loss: 0.380\n",
      "Train accuracy: tensor(84.5771, device='cuda:0')\n",
      "Test accuracy: tensor(84.0174, device='cuda:0')\n",
      "[1,114500] loss: 0.373\n",
      "[1,115000] loss: 0.368\n",
      "[1,115500] loss: 0.384\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#optimizer3 = optim.SGD(my_model.parameters(),lr=learning_rate,momentum=.9)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion3\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, num_epochs, trainloader, testloader)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      4\u001b[0m     running_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i , (label, anchor, sample) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[0;32m      7\u001b[0m         anchor \u001b[38;5;241m=\u001b[39m anchor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m         sample \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\Documents\\Chess_Engine\\Chess_Enviorment\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\Documents\\Chess_Engine\\Chess_Enviorment\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\Documents\\Chess_Engine\\Chess_Enviorment\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\Documents\\Chess_Engine\\Chess_Enviorment\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\Documents\\Chess_Engine\\Chess_Enviorment\\lib\\site-packages\\torch\\utils\\data\\dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Chess_Engine\\Triplet_Dataset.py:28\u001b[0m, in \u001b[0;36mTripletData.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtriplet_convert_classifier(info, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriplet_convert_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Chess_Engine\\Triplet_Dataset.py:54\u001b[0m, in \u001b[0;36mTripletData.triplet_convert_classifier\u001b[1;34m(self, data, pos_neg_bool)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 54\u001b[0m anchor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmove\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos_neg_bool:\n\u001b[0;32m     56\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_data(data[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39mmove)\n",
      "File \u001b[1;32m~\\Documents\\Chess_Engine\\Triplet_Dataset.py:96\u001b[0m, in \u001b[0;36mTripletData.convert_data\u001b[1;34m(self, data, move)\u001b[0m\n\u001b[0;32m     94\u001b[0m arr\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mmove\n\u001b[0;32m     95\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(arr)\n\u001b[1;32m---> 96\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "learning_rate = .5e-3\n",
    "num_epochs = 10\n",
    "criterion3 = nn.BCEWithLogitsLoss()\n",
    "optimizer3=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "#optimizer3 = optim.SGD(my_model.parameters(),lr=learning_rate,momentum=.9)\n",
    "num_epochs=15\n",
    "train(model,criterion3,optimizer3,num_epochs,trainloader,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "350fe3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './previous_models/ScoreNetL2-84.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8adf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chess_Enviorment",
   "language": "python",
   "name": "chess_enviorment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
