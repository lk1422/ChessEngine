{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "exceptional-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader  \n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms  # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "thrown-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chess_Data import ChessData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "silent-review",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4cab9b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test_Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(7,128, kernel_size=3,stride=1)\n",
    "        self.max = nn.MaxPool2d(2,2)\n",
    "        self.linear = nn.Sequential(nn.Linear(9*128, 512), nn.ReLU(), nn.Linear(512,512), nn.ReLU(), nn.Linear(512,128),\n",
    "                                   nn.ReLU(), nn.Linear(128,64), nn.ReLU(), nn.Linear(64,2))\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.normal_(self.conv1.weight,0, 1e-7)\n",
    "        torch.nn.init.normal_(self.conv2.weight,0, 1e-7)\n",
    "        torch.nn.init.normal_(self.conv3.weight,0, 1e-7)\n",
    "        torch.nn.init.normal_(self.conv4.weight,0, 1e-6)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "integral-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset =  ChessData('training.csv')\n",
    "trainloader= torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "loved-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,criterion,optimizer,num_epochs,trainloader):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss=0.0\n",
    "        \n",
    "        for i , (  targets, data) in enumerate(trainloader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            targets= targets.to(device)\n",
    "            targets = targets.to(torch.int64)\n",
    "\n",
    "            #forward prop\n",
    "            scores = model(data).squeeze()\n",
    "            \n",
    "\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #take step\n",
    "            optimizer.step()\n",
    "            losss= loss.item()\n",
    "            \n",
    "            running_loss+=losss\n",
    "            \n",
    "            \n",
    "           \n",
    "            if i %500==499:\n",
    "                print('[%d,%5d] loss: %.3f' % (epoch+1 , i+1, running_loss/500))\n",
    "                running_loss=0.0\n",
    "            if i % 2000 == 1999: \n",
    "                print(\"Train accuracy: \"+ str(check_accuracy(trainloader, model)*100))\n",
    "               # print(\"Test accuracy: \"+ str(check_accuracy(testloader, model)*100))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "advised-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, full=False):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for  i ,( y, x) in enumerate(loader):\n",
    "            if i >100 and not full:\n",
    "\n",
    "                return num_correct/num_samples\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y =y.to(torch.int64)\n",
    "           \n",
    "\n",
    "            scores = model(x)\n",
    "            \n",
    "            \n",
    "            _, predictions = scores.max(1)\n",
    "            \n",
    "            num_correct += (predictions == y).sum()\n",
    "            \n",
    "         \n",
    "            \n",
    "            \n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "literary-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Test_Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-canada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  500] loss: 0.502\n",
      "[1, 1000] loss: 0.498\n",
      "[1, 1500] loss: 0.497\n",
      "[1, 2000] loss: 0.492\n",
      "Train accuracy: tensor(75.1238, device='cuda:0')\n",
      "[1, 2500] loss: 0.512\n",
      "[1, 3000] loss: 0.493\n",
      "[1, 3500] loss: 0.498\n",
      "[1, 4000] loss: 0.501\n",
      "Train accuracy: tensor(74.0718, device='cuda:0')\n",
      "[1, 4500] loss: 0.500\n",
      "[1, 5000] loss: 0.496\n",
      "[1, 5500] loss: 0.501\n",
      "[1, 6000] loss: 0.497\n",
      "Train accuracy: tensor(73.1436, device='cuda:0')\n",
      "[1, 6500] loss: 0.506\n",
      "[1, 7000] loss: 0.483\n",
      "[1, 7500] loss: 0.491\n",
      "[1, 8000] loss: 0.499\n",
      "Train accuracy: tensor(76.3614, device='cuda:0')\n",
      "[1, 8500] loss: 0.513\n",
      "[1, 9000] loss: 0.488\n",
      "[1, 9500] loss: 0.502\n",
      "[1,10000] loss: 0.502\n",
      "Train accuracy: tensor(73.7624, device='cuda:0')\n",
      "[1,10500] loss: 0.488\n",
      "[1,11000] loss: 0.504\n",
      "[1,11500] loss: 0.498\n",
      "[1,12000] loss: 0.498\n",
      "Train accuracy: tensor(75.4950, device='cuda:0')\n",
      "[1,12500] loss: 0.487\n",
      "[1,13000] loss: 0.494\n",
      "[1,13500] loss: 0.496\n",
      "[1,14000] loss: 0.502\n",
      "Train accuracy: tensor(75.6807, device='cuda:0')\n",
      "[1,14500] loss: 0.496\n",
      "[1,15000] loss: 0.496\n",
      "[1,15500] loss: 0.496\n",
      "[1,16000] loss: 0.496\n",
      "Train accuracy: tensor(74.1955, device='cuda:0')\n",
      "[1,16500] loss: 0.495\n",
      "[1,17000] loss: 0.497\n",
      "[1,17500] loss: 0.497\n",
      "[1,18000] loss: 0.495\n",
      "Train accuracy: tensor(74.6287, device='cuda:0')\n",
      "[1,18500] loss: 0.487\n",
      "[1,19000] loss: 0.496\n",
      "[1,19500] loss: 0.508\n",
      "[1,20000] loss: 0.509\n",
      "Train accuracy: tensor(74.9381, device='cuda:0')\n",
      "[1,20500] loss: 0.500\n",
      "[1,21000] loss: 0.494\n",
      "[1,21500] loss: 0.504\n",
      "[1,22000] loss: 0.493\n",
      "Train accuracy: tensor(75.9901, device='cuda:0')\n",
      "[1,22500] loss: 0.505\n",
      "[1,23000] loss: 0.502\n",
      "[1,23500] loss: 0.492\n",
      "[1,24000] loss: 0.493\n",
      "Train accuracy: tensor(74.8762, device='cuda:0')\n",
      "[1,24500] loss: 0.495\n",
      "[1,25000] loss: 0.498\n",
      "[1,25500] loss: 0.493\n",
      "[1,26000] loss: 0.496\n",
      "Train accuracy: tensor(75.2475, device='cuda:0')\n",
      "[1,26500] loss: 0.503\n",
      "[1,27000] loss: 0.503\n",
      "[1,27500] loss: 0.499\n",
      "[1,28000] loss: 0.496\n",
      "Train accuracy: tensor(74.3812, device='cuda:0')\n",
      "[1,28500] loss: 0.502\n",
      "[1,29000] loss: 0.490\n",
      "[1,29500] loss: 0.501\n",
      "[1,30000] loss: 0.497\n",
      "Train accuracy: tensor(75., device='cuda:0')\n",
      "[1,30500] loss: 0.491\n",
      "[1,31000] loss: 0.495\n",
      "[1,31500] loss: 0.498\n",
      "[1,32000] loss: 0.496\n",
      "Train accuracy: tensor(75.9282, device='cuda:0')\n",
      "[1,32500] loss: 0.507\n",
      "[1,33000] loss: 0.497\n",
      "[1,33500] loss: 0.496\n",
      "[1,34000] loss: 0.503\n",
      "Train accuracy: tensor(74.5668, device='cuda:0')\n",
      "[1,34500] loss: 0.502\n",
      "[1,35000] loss: 0.495\n",
      "[1,35500] loss: 0.506\n",
      "[1,36000] loss: 0.500\n",
      "Train accuracy: tensor(75.1856, device='cuda:0')\n",
      "[1,36500] loss: 0.508\n",
      "[1,37000] loss: 0.495\n",
      "[1,37500] loss: 0.500\n",
      "[1,38000] loss: 0.504\n",
      "Train accuracy: tensor(74.0718, device='cuda:0')\n",
      "[1,38500] loss: 0.497\n",
      "[1,39000] loss: 0.494\n",
      "[1,39500] loss: 0.496\n",
      "[1,40000] loss: 0.498\n",
      "Train accuracy: tensor(75., device='cuda:0')\n",
      "[1,40500] loss: 0.504\n",
      "[1,41000] loss: 0.500\n",
      "[1,41500] loss: 0.495\n",
      "[1,42000] loss: 0.502\n",
      "Train accuracy: tensor(74.0718, device='cuda:0')\n",
      "[1,42500] loss: 0.493\n",
      "[1,43000] loss: 0.501\n",
      "[1,43500] loss: 0.499\n",
      "[1,44000] loss: 0.498\n",
      "Train accuracy: tensor(75.1856, device='cuda:0')\n",
      "[1,44500] loss: 0.502\n",
      "[1,45000] loss: 0.499\n",
      "[1,45500] loss: 0.500\n",
      "[1,46000] loss: 0.504\n",
      "Train accuracy: tensor(77.5371, device='cuda:0')\n",
      "[1,46500] loss: 0.500\n",
      "[1,47000] loss: 0.486\n",
      "[1,47500] loss: 0.494\n",
      "[1,48000] loss: 0.500\n",
      "Train accuracy: tensor(75.7426, device='cuda:0')\n",
      "[1,48500] loss: 0.493\n",
      "[1,49000] loss: 0.495\n",
      "[1,49500] loss: 0.487\n",
      "[1,50000] loss: 0.507\n",
      "Train accuracy: tensor(74.3193, device='cuda:0')\n",
      "[1,50500] loss: 0.490\n",
      "[1,51000] loss: 0.494\n",
      "[1,51500] loss: 0.497\n",
      "[1,52000] loss: 0.502\n",
      "Train accuracy: tensor(74.3812, device='cuda:0')\n",
      "[1,52500] loss: 0.512\n",
      "[1,53000] loss: 0.502\n",
      "[1,53500] loss: 0.501\n",
      "[1,54000] loss: 0.501\n",
      "Train accuracy: tensor(75.3713, device='cuda:0')\n",
      "[1,54500] loss: 0.504\n",
      "[1,55000] loss: 0.500\n",
      "[1,55500] loss: 0.500\n",
      "[1,56000] loss: 0.484\n",
      "Train accuracy: tensor(74.6287, device='cuda:0')\n",
      "[1,56500] loss: 0.501\n",
      "[1,57000] loss: 0.502\n",
      "[1,57500] loss: 0.497\n",
      "[1,58000] loss: 0.496\n",
      "Train accuracy: tensor(74.0099, device='cuda:0')\n",
      "[1,58500] loss: 0.498\n",
      "[1,59000] loss: 0.504\n",
      "[1,59500] loss: 0.498\n",
      "[1,60000] loss: 0.505\n",
      "Train accuracy: tensor(75.5569, device='cuda:0')\n",
      "[1,60500] loss: 0.494\n",
      "[1,61000] loss: 0.499\n",
      "[1,61500] loss: 0.498\n",
      "[1,62000] loss: 0.498\n",
      "Train accuracy: tensor(75.1856, device='cuda:0')\n",
      "[1,62500] loss: 0.493\n",
      "[1,63000] loss: 0.504\n",
      "[1,63500] loss: 0.503\n",
      "[1,64000] loss: 0.504\n",
      "Train accuracy: tensor(72.0297, device='cuda:0')\n",
      "[1,64500] loss: 0.501\n",
      "[1,65000] loss: 0.501\n",
      "[1,65500] loss: 0.487\n",
      "[1,66000] loss: 0.499\n",
      "Train accuracy: tensor(73.8861, device='cuda:0')\n",
      "[1,66500] loss: 0.503\n",
      "[1,67000] loss: 0.498\n",
      "[1,67500] loss: 0.496\n",
      "[1,68000] loss: 0.490\n",
      "Train accuracy: tensor(75.2475, device='cuda:0')\n",
      "[1,68500] loss: 0.497\n",
      "[1,69000] loss: 0.502\n",
      "[1,69500] loss: 0.502\n",
      "[1,70000] loss: 0.505\n",
      "Train accuracy: tensor(74.6906, device='cuda:0')\n",
      "[1,70500] loss: 0.506\n",
      "[1,71000] loss: 0.496\n",
      "[1,71500] loss: 0.491\n",
      "[1,72000] loss: 0.510\n",
      "Train accuracy: tensor(73.4530, device='cuda:0')\n",
      "[1,72500] loss: 0.501\n",
      "[1,73000] loss: 0.497\n",
      "[1,73500] loss: 0.491\n",
      "[1,74000] loss: 0.485\n",
      "Train accuracy: tensor(77.5990, device='cuda:0')\n",
      "[1,74500] loss: 0.496\n",
      "[1,75000] loss: 0.496\n",
      "[1,75500] loss: 0.502\n",
      "[1,76000] loss: 0.506\n",
      "Train accuracy: tensor(75.9282, device='cuda:0')\n",
      "[1,76500] loss: 0.498\n",
      "[1,77000] loss: 0.497\n",
      "[1,77500] loss: 0.504\n",
      "[1,78000] loss: 0.499\n",
      "Train accuracy: tensor(73.9480, device='cuda:0')\n",
      "[1,78500] loss: 0.498\n",
      "[1,79000] loss: 0.497\n",
      "[1,79500] loss: 0.501\n",
      "[1,80000] loss: 0.493\n",
      "Train accuracy: tensor(73.7624, device='cuda:0')\n",
      "[1,80500] loss: 0.508\n",
      "[1,81000] loss: 0.502\n",
      "[1,81500] loss: 0.503\n",
      "[1,82000] loss: 0.494\n",
      "Train accuracy: tensor(76.1139, device='cuda:0')\n",
      "[1,82500] loss: 0.496\n",
      "[1,83000] loss: 0.499\n",
      "[1,83500] loss: 0.499\n",
      "[1,84000] loss: 0.495\n",
      "Train accuracy: tensor(75.5569, device='cuda:0')\n",
      "[1,84500] loss: 0.493\n",
      "[1,85000] loss: 0.492\n",
      "[1,85500] loss: 0.490\n",
      "[1,86000] loss: 0.499\n",
      "Train accuracy: tensor(74.8762, device='cuda:0')\n",
      "[1,86500] loss: 0.498\n",
      "[1,87000] loss: 0.506\n",
      "[1,87500] loss: 0.506\n",
      "[1,88000] loss: 0.484\n",
      "Train accuracy: tensor(73.7005, device='cuda:0')\n",
      "[1,88500] loss: 0.496\n",
      "[1,89000] loss: 0.496\n",
      "[1,89500] loss: 0.496\n",
      "[1,90000] loss: 0.507\n",
      "Train accuracy: tensor(73.7005, device='cuda:0')\n",
      "[1,90500] loss: 0.498\n",
      "[1,91000] loss: 0.501\n",
      "[1,91500] loss: 0.500\n",
      "[1,92000] loss: 0.490\n",
      "Train accuracy: tensor(76.1139, device='cuda:0')\n",
      "[1,92500] loss: 0.499\n",
      "[1,93000] loss: 0.495\n",
      "[1,93500] loss: 0.505\n",
      "[1,94000] loss: 0.496\n",
      "Train accuracy: tensor(76.0520, device='cuda:0')\n",
      "[1,94500] loss: 0.492\n",
      "[1,95000] loss: 0.496\n",
      "[1,95500] loss: 0.507\n",
      "[1,96000] loss: 0.513\n",
      "Train accuracy: tensor(74.6906, device='cuda:0')\n",
      "[1,96500] loss: 0.495\n",
      "[1,97000] loss: 0.498\n",
      "[1,97500] loss: 0.499\n",
      "[1,98000] loss: 0.483\n",
      "Train accuracy: tensor(75.2475, device='cuda:0')\n",
      "[1,98500] loss: 0.502\n",
      "[1,99000] loss: 0.500\n",
      "[1,99500] loss: 0.497\n",
      "[1,100000] loss: 0.500\n",
      "Train accuracy: tensor(75.0619, device='cuda:0')\n",
      "[1,100500] loss: 0.499\n",
      "[1,101000] loss: 0.501\n",
      "[1,101500] loss: 0.496\n",
      "[1,102000] loss: 0.496\n",
      "Train accuracy: tensor(74.8144, device='cuda:0')\n",
      "[1,102500] loss: 0.499\n",
      "[1,103000] loss: 0.503\n",
      "[1,103500] loss: 0.498\n",
      "[1,104000] loss: 0.502\n",
      "Train accuracy: tensor(72.7723, device='cuda:0')\n",
      "[1,104500] loss: 0.498\n",
      "[1,105000] loss: 0.489\n",
      "[1,105500] loss: 0.514\n",
      "[1,106000] loss: 0.496\n",
      "Train accuracy: tensor(75., device='cuda:0')\n",
      "[1,106500] loss: 0.491\n",
      "[1,107000] loss: 0.502\n",
      "[1,107500] loss: 0.499\n",
      "[1,108000] loss: 0.505\n",
      "Train accuracy: tensor(76.0520, device='cuda:0')\n",
      "[1,108500] loss: 0.496\n",
      "[1,109000] loss: 0.507\n",
      "[1,109500] loss: 0.500\n",
      "[1,110000] loss: 0.502\n",
      "Train accuracy: tensor(75., device='cuda:0')\n",
      "[1,110500] loss: 0.496\n",
      "[1,111000] loss: 0.502\n",
      "[1,111500] loss: 0.504\n",
      "[1,112000] loss: 0.507\n",
      "Train accuracy: tensor(73.3911, device='cuda:0')\n",
      "[1,112500] loss: 0.495\n",
      "[1,113000] loss: 0.492\n",
      "[1,113500] loss: 0.498\n",
      "[1,114000] loss: 0.508\n",
      "Train accuracy: tensor(75.9901, device='cuda:0')\n",
      "[1,114500] loss: 0.501\n",
      "[1,115000] loss: 0.494\n",
      "[1,115500] loss: 0.497\n",
      "[1,116000] loss: 0.504\n",
      "Train accuracy: tensor(74.5049, device='cuda:0')\n",
      "[1,116500] loss: 0.504\n",
      "[1,117000] loss: 0.499\n",
      "[1,117500] loss: 0.494\n",
      "[1,118000] loss: 0.492\n",
      "Train accuracy: tensor(76.3614, device='cuda:0')\n",
      "[1,118500] loss: 0.498\n",
      "[1,119000] loss: 0.503\n",
      "[1,119500] loss: 0.499\n",
      "[1,120000] loss: 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: tensor(76.7327, device='cuda:0')\n",
      "[1,120500] loss: 0.497\n",
      "[1,121000] loss: 0.508\n",
      "[1,121500] loss: 0.509\n",
      "[1,122000] loss: 0.496\n",
      "Train accuracy: tensor(72.7723, device='cuda:0')\n",
      "[1,122500] loss: 0.490\n",
      "[1,123000] loss: 0.505\n",
      "[1,123500] loss: 0.502\n",
      "[1,124000] loss: 0.500\n",
      "Train accuracy: tensor(75.2475, device='cuda:0')\n",
      "[1,124500] loss: 0.493\n",
      "[1,125000] loss: 0.507\n",
      "[1,125500] loss: 0.499\n",
      "[1,126000] loss: 0.488\n",
      "Train accuracy: tensor(74.8144, device='cuda:0')\n",
      "[1,126500] loss: 0.494\n",
      "[1,127000] loss: 0.497\n",
      "[1,127500] loss: 0.490\n",
      "[1,128000] loss: 0.493\n",
      "Train accuracy: tensor(75.9901, device='cuda:0')\n",
      "[1,128500] loss: 0.498\n",
      "[1,129000] loss: 0.495\n",
      "[1,129500] loss: 0.500\n",
      "[1,130000] loss: 0.505\n",
      "Train accuracy: tensor(75.6188, device='cuda:0')\n",
      "[1,130500] loss: 0.500\n",
      "[1,131000] loss: 0.485\n",
      "[1,131500] loss: 0.495\n",
      "[1,132000] loss: 0.503\n",
      "Train accuracy: tensor(73.3292, device='cuda:0')\n",
      "[1,132500] loss: 0.499\n",
      "[1,133000] loss: 0.486\n",
      "[1,133500] loss: 0.484\n",
      "[1,134000] loss: 0.495\n",
      "Train accuracy: tensor(75.8045, device='cuda:0')\n",
      "[1,134500] loss: 0.491\n",
      "[1,135000] loss: 0.496\n",
      "[1,135500] loss: 0.501\n",
      "[1,136000] loss: 0.496\n",
      "Train accuracy: tensor(75.1238, device='cuda:0')\n",
      "[1,136500] loss: 0.505\n",
      "[1,137000] loss: 0.492\n",
      "[1,137500] loss: 0.494\n",
      "[1,138000] loss: 0.489\n",
      "Train accuracy: tensor(74.6906, device='cuda:0')\n",
      "[1,138500] loss: 0.499\n",
      "[1,139000] loss: 0.494\n",
      "[1,139500] loss: 0.502\n",
      "[1,140000] loss: 0.505\n",
      "Train accuracy: tensor(74.8144, device='cuda:0')\n",
      "[1,140500] loss: 0.488\n",
      "[1,141000] loss: 0.497\n",
      "[1,141500] loss: 0.506\n",
      "[1,142000] loss: 0.497\n",
      "Train accuracy: tensor(73.8243, device='cuda:0')\n",
      "[1,142500] loss: 0.493\n",
      "[1,143000] loss: 0.496\n",
      "[1,143500] loss: 0.508\n",
      "[1,144000] loss: 0.487\n",
      "Train accuracy: tensor(77.3515, device='cuda:0')\n",
      "[1,144500] loss: 0.503\n",
      "[1,145000] loss: 0.494\n",
      "[1,145500] loss: 0.495\n",
      "[1,146000] loss: 0.497\n",
      "Train accuracy: tensor(75.8045, device='cuda:0')\n",
      "[1,146500] loss: 0.493\n",
      "[1,147000] loss: 0.494\n",
      "[1,147500] loss: 0.495\n",
      "[1,148000] loss: 0.501\n",
      "Train accuracy: tensor(74.5668, device='cuda:0')\n",
      "[1,148500] loss: 0.500\n",
      "[1,149000] loss: 0.491\n",
      "[1,149500] loss: 0.500\n",
      "[1,150000] loss: 0.497\n",
      "Train accuracy: tensor(74.1955, device='cuda:0')\n",
      "[1,150500] loss: 0.509\n",
      "[1,151000] loss: 0.500\n",
      "[1,151500] loss: 0.505\n",
      "[1,152000] loss: 0.497\n",
      "Train accuracy: tensor(74.8144, device='cuda:0')\n",
      "[1,152500] loss: 0.500\n",
      "[1,153000] loss: 0.492\n",
      "[1,153500] loss: 0.499\n",
      "[1,154000] loss: 0.503\n",
      "Train accuracy: tensor(75.6188, device='cuda:0')\n",
      "[1,154500] loss: 0.497\n",
      "[1,155000] loss: 0.504\n",
      "[1,155500] loss: 0.514\n",
      "[1,156000] loss: 0.491\n",
      "Train accuracy: tensor(75.2475, device='cuda:0')\n",
      "[1,156500] loss: 0.497\n",
      "[1,157000] loss: 0.492\n",
      "[1,157500] loss: 0.495\n",
      "[1,158000] loss: 0.503\n",
      "Train accuracy: tensor(74.3193, device='cuda:0')\n",
      "[1,158500] loss: 0.503\n",
      "[1,159000] loss: 0.496\n",
      "[1,159500] loss: 0.505\n",
      "[1,160000] loss: 0.501\n",
      "Train accuracy: tensor(72.8342, device='cuda:0')\n",
      "[1,160500] loss: 0.499\n",
      "[1,161000] loss: 0.493\n",
      "[1,161500] loss: 0.499\n",
      "[1,162000] loss: 0.504\n",
      "Train accuracy: tensor(76.5470, device='cuda:0')\n",
      "[1,162500] loss: 0.505\n",
      "[1,163000] loss: 0.506\n",
      "[1,163500] loss: 0.507\n",
      "[1,164000] loss: 0.499\n",
      "Train accuracy: tensor(72.6485, device='cuda:0')\n",
      "[1,164500] loss: 0.493\n",
      "[1,165000] loss: 0.508\n",
      "[1,165500] loss: 0.494\n",
      "[1,166000] loss: 0.503\n",
      "Train accuracy: tensor(77.0421, device='cuda:0')\n",
      "[1,166500] loss: 0.498\n",
      "[1,167000] loss: 0.491\n",
      "[1,167500] loss: 0.495\n",
      "[1,168000] loss: 0.517\n",
      "Train accuracy: tensor(72.7723, device='cuda:0')\n",
      "[1,168500] loss: 0.499\n",
      "[1,169000] loss: 0.496\n",
      "[1,169500] loss: 0.505\n",
      "[1,170000] loss: 0.496\n",
      "Train accuracy: tensor(73.2054, device='cuda:0')\n",
      "[1,170500] loss: 0.507\n",
      "[1,171000] loss: 0.497\n",
      "[1,171500] loss: 0.502\n",
      "[1,172000] loss: 0.484\n",
      "Train accuracy: tensor(75.3713, device='cuda:0')\n",
      "[1,172500] loss: 0.507\n",
      "[1,173000] loss: 0.507\n",
      "[1,173500] loss: 0.500\n",
      "[1,174000] loss: 0.498\n",
      "Train accuracy: tensor(74.7525, device='cuda:0')\n",
      "[1,174500] loss: 0.504\n",
      "[1,175000] loss: 0.483\n",
      "[1,175500] loss: 0.510\n",
      "[1,176000] loss: 0.502\n",
      "Train accuracy: tensor(74.5049, device='cuda:0')\n",
      "[1,176500] loss: 0.495\n",
      "[1,177000] loss: 0.499\n",
      "[1,177500] loss: 0.497\n",
      "[1,178000] loss: 0.492\n",
      "Train accuracy: tensor(74.8144, device='cuda:0')\n",
      "[1,178500] loss: 0.500\n",
      "[1,179000] loss: 0.495\n",
      "[1,179500] loss: 0.495\n",
      "[1,180000] loss: 0.507\n",
      "Train accuracy: tensor(73.9480, device='cuda:0')\n",
      "[1,180500] loss: 0.489\n",
      "[1,181000] loss: 0.498\n",
      "[1,181500] loss: 0.500\n",
      "[1,182000] loss: 0.494\n",
      "Train accuracy: tensor(74.0718, device='cuda:0')\n",
      "[1,182500] loss: 0.499\n",
      "[1,183000] loss: 0.502\n",
      "[1,183500] loss: 0.496\n",
      "[1,184000] loss: 0.502\n",
      "Train accuracy: tensor(74.7525, device='cuda:0')\n",
      "[1,184500] loss: 0.494\n",
      "[1,185000] loss: 0.496\n",
      "[1,185500] loss: 0.494\n",
      "[1,186000] loss: 0.501\n",
      "Train accuracy: tensor(74.5668, device='cuda:0')\n",
      "[1,186500] loss: 0.495\n",
      "[1,187000] loss: 0.494\n",
      "[1,187500] loss: 0.497\n",
      "[1,188000] loss: 0.497\n",
      "Train accuracy: tensor(75.3094, device='cuda:0')\n",
      "[1,188500] loss: 0.503\n",
      "[1,189000] loss: 0.499\n",
      "[1,189500] loss: 0.491\n",
      "[1,190000] loss: 0.494\n",
      "Train accuracy: tensor(75.0619, device='cuda:0')\n",
      "[1,190500] loss: 0.495\n",
      "[1,191000] loss: 0.500\n",
      "[1,191500] loss: 0.494\n",
      "[1,192000] loss: 0.503\n",
      "Train accuracy: tensor(76.5470, device='cuda:0')\n",
      "[1,192500] loss: 0.502\n",
      "[1,193000] loss: 0.497\n",
      "[1,193500] loss: 0.506\n",
      "[1,194000] loss: 0.494\n",
      "Train accuracy: tensor(74.0718, device='cuda:0')\n",
      "[1,194500] loss: 0.498\n",
      "[1,195000] loss: 0.509\n",
      "[1,195500] loss: 0.505\n",
      "[1,196000] loss: 0.506\n",
      "Train accuracy: tensor(73.8243, device='cuda:0')\n",
      "[1,196500] loss: 0.505\n",
      "[1,197000] loss: 0.509\n",
      "[1,197500] loss: 0.505\n",
      "[1,198000] loss: 0.503\n",
      "Train accuracy: tensor(74.9381, device='cuda:0')\n",
      "[1,198500] loss: 0.504\n",
      "[1,199000] loss: 0.491\n",
      "[1,199500] loss: 0.492\n",
      "[1,200000] loss: 0.495\n",
      "Train accuracy: tensor(75.1856, device='cuda:0')\n",
      "[1,200500] loss: 0.500\n",
      "[1,201000] loss: 0.498\n",
      "[1,201500] loss: 0.499\n",
      "[1,202000] loss: 0.505\n",
      "Train accuracy: tensor(76.8564, device='cuda:0')\n",
      "[1,202500] loss: 0.507\n",
      "[1,203000] loss: 0.495\n",
      "[1,203500] loss: 0.492\n",
      "[1,204000] loss: 0.500\n",
      "Train accuracy: tensor(74.3812, device='cuda:0')\n",
      "[1,204500] loss: 0.495\n",
      "[1,205000] loss: 0.492\n",
      "[1,205500] loss: 0.494\n",
      "[1,206000] loss: 0.506\n",
      "Train accuracy: tensor(75.7426, device='cuda:0')\n",
      "[1,206500] loss: 0.500\n",
      "[1,207000] loss: 0.495\n",
      "[1,207500] loss: 0.496\n",
      "[1,208000] loss: 0.496\n",
      "Train accuracy: tensor(74.5049, device='cuda:0')\n",
      "[1,208500] loss: 0.502\n",
      "[1,209000] loss: 0.496\n",
      "[1,209500] loss: 0.501\n",
      "[1,210000] loss: 0.505\n",
      "Train accuracy: tensor(74.2574, device='cuda:0')\n",
      "[1,210500] loss: 0.498\n",
      "[1,211000] loss: 0.495\n",
      "[1,211500] loss: 0.489\n",
      "[1,212000] loss: 0.490\n",
      "Train accuracy: tensor(74.5049, device='cuda:0')\n",
      "[1,212500] loss: 0.502\n",
      "[1,213000] loss: 0.505\n",
      "[1,213500] loss: 0.487\n",
      "[1,214000] loss: 0.499\n",
      "Train accuracy: tensor(75.6188, device='cuda:0')\n",
      "[1,214500] loss: 0.497\n",
      "[1,215000] loss: 0.498\n",
      "[1,215500] loss: 0.488\n",
      "[1,216000] loss: 0.496\n",
      "Train accuracy: tensor(75.4332, device='cuda:0')\n",
      "[1,216500] loss: 0.495\n",
      "[1,217000] loss: 0.495\n",
      "[1,217500] loss: 0.490\n",
      "[1,218000] loss: 0.490\n",
      "Train accuracy: tensor(73.7624, device='cuda:0')\n",
      "[1,218500] loss: 0.500\n",
      "[1,219000] loss: 0.504\n",
      "[1,219500] loss: 0.494\n",
      "[1,220000] loss: 0.501\n",
      "Train accuracy: tensor(72.4010, device='cuda:0')\n",
      "[1,220500] loss: 0.503\n",
      "[1,221000] loss: 0.497\n",
      "[1,221500] loss: 0.479\n",
      "[1,222000] loss: 0.483\n",
      "Train accuracy: tensor(74.1955, device='cuda:0')\n",
      "[1,222500] loss: 0.493\n",
      "[1,223000] loss: 0.494\n",
      "[1,223500] loss: 0.498\n",
      "[1,224000] loss: 0.493\n",
      "Train accuracy: tensor(74.6906, device='cuda:0')\n",
      "[1,224500] loss: 0.499\n",
      "[1,225000] loss: 0.503\n",
      "[1,225500] loss: 0.501\n",
      "[1,226000] loss: 0.501\n",
      "Train accuracy: tensor(77.5371, device='cuda:0')\n",
      "[1,226500] loss: 0.499\n",
      "[1,227000] loss: 0.505\n",
      "[1,227500] loss: 0.496\n",
      "[1,228000] loss: 0.495\n",
      "Train accuracy: tensor(74.8762, device='cuda:0')\n",
      "[1,228500] loss: 0.489\n",
      "[1,229000] loss: 0.498\n",
      "[1,229500] loss: 0.508\n",
      "[1,230000] loss: 0.495\n",
      "Train accuracy: tensor(74.9381, device='cuda:0')\n",
      "[1,230500] loss: 0.509\n",
      "[1,231000] loss: 0.490\n",
      "[1,231500] loss: 0.502\n",
      "[1,232000] loss: 0.500\n",
      "Train accuracy: tensor(75.7426, device='cuda:0')\n",
      "[1,232500] loss: 0.490\n",
      "[1,233000] loss: 0.503\n",
      "[1,233500] loss: 0.508\n",
      "[1,234000] loss: 0.498\n",
      "Train accuracy: tensor(74.8762, device='cuda:0')\n",
      "[1,234500] loss: 0.496\n",
      "[1,235000] loss: 0.504\n",
      "[1,235500] loss: 0.506\n",
      "[1,236000] loss: 0.511\n",
      "Train accuracy: tensor(74.6906, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,236500] loss: 0.503\n",
      "[1,237000] loss: 0.496\n",
      "[1,237500] loss: 0.504\n",
      "[1,238000] loss: 0.504\n",
      "Train accuracy: tensor(74.8144, device='cuda:0')\n",
      "[1,238500] loss: 0.489\n",
      "[1,239000] loss: 0.497\n",
      "[1,239500] loss: 0.506\n",
      "[1,240000] loss: 0.502\n",
      "Train accuracy: tensor(75.5569, device='cuda:0')\n",
      "[1,240500] loss: 0.512\n",
      "[1,241000] loss: 0.499\n",
      "[1,241500] loss: 0.494\n",
      "[1,242000] loss: 0.505\n",
      "Train accuracy: tensor(75.6188, device='cuda:0')\n",
      "[1,242500] loss: 0.508\n",
      "[1,243000] loss: 0.495\n",
      "[1,243500] loss: 0.498\n",
      "[1,244000] loss: 0.509\n",
      "Train accuracy: tensor(74.1337, device='cuda:0')\n",
      "[1,244500] loss: 0.501\n",
      "[1,245000] loss: 0.493\n",
      "[1,245500] loss: 0.491\n",
      "[1,246000] loss: 0.495\n",
      "Train accuracy: tensor(74.8762, device='cuda:0')\n",
      "[1,246500] loss: 0.508\n",
      "[1,247000] loss: 0.504\n",
      "[1,247500] loss: 0.503\n",
      "[1,248000] loss: 0.503\n",
      "Train accuracy: tensor(74.3193, device='cuda:0')\n",
      "[1,248500] loss: 0.494\n",
      "[1,249000] loss: 0.496\n",
      "[1,249500] loss: 0.496\n",
      "[1,250000] loss: 0.490\n",
      "Train accuracy: tensor(73.9480, device='cuda:0')\n",
      "[1,250500] loss: 0.506\n",
      "[1,251000] loss: 0.496\n",
      "[1,251500] loss: 0.500\n",
      "[1,252000] loss: 0.499\n",
      "Train accuracy: tensor(77.5371, device='cuda:0')\n",
      "[1,252500] loss: 0.496\n",
      "[1,253000] loss: 0.506\n",
      "[1,253500] loss: 0.506\n",
      "[1,254000] loss: 0.496\n",
      "Train accuracy: tensor(75.3713, device='cuda:0')\n",
      "[1,254500] loss: 0.497\n",
      "[1,255000] loss: 0.499\n",
      "[1,255500] loss: 0.506\n",
      "[1,256000] loss: 0.500\n",
      "Train accuracy: tensor(76.2995, device='cuda:0')\n",
      "[1,256500] loss: 0.505\n",
      "[1,257000] loss: 0.504\n",
      "[1,257500] loss: 0.485\n",
      "[1,258000] loss: 0.490\n",
      "Train accuracy: tensor(73.7005, device='cuda:0')\n",
      "[1,258500] loss: 0.500\n",
      "[1,259000] loss: 0.511\n",
      "[1,259500] loss: 0.504\n",
      "[1,260000] loss: 0.492\n",
      "Train accuracy: tensor(74.1955, device='cuda:0')\n",
      "[1,260500] loss: 0.495\n",
      "[1,261000] loss: 0.501\n",
      "[1,261500] loss: 0.501\n",
      "[1,262000] loss: 0.507\n",
      "Train accuracy: tensor(75.4950, device='cuda:0')\n",
      "[1,262500] loss: 0.506\n",
      "[1,263000] loss: 0.498\n",
      "[1,263500] loss: 0.489\n",
      "[1,264000] loss: 0.495\n",
      "Train accuracy: tensor(78.0322, device='cuda:0')\n",
      "[1,264500] loss: 0.495\n",
      "[1,265000] loss: 0.500\n",
      "[1,265500] loss: 0.500\n",
      "[1,266000] loss: 0.493\n",
      "Train accuracy: tensor(75.3094, device='cuda:0')\n",
      "[1,266500] loss: 0.492\n",
      "[1,267000] loss: 0.482\n",
      "[1,267500] loss: 0.499\n",
      "[1,268000] loss: 0.497\n",
      "Train accuracy: tensor(75.4332, device='cuda:0')\n",
      "[1,268500] loss: 0.495\n",
      "[1,269000] loss: 0.500\n",
      "[1,269500] loss: 0.508\n",
      "[1,270000] loss: 0.497\n",
      "Train accuracy: tensor(74.6906, device='cuda:0')\n",
      "[1,270500] loss: 0.503\n",
      "[1,271000] loss: 0.493\n",
      "[1,271500] loss: 0.493\n",
      "[1,272000] loss: 0.495\n",
      "Train accuracy: tensor(77.4134, device='cuda:0')\n",
      "[1,272500] loss: 0.492\n",
      "[1,273000] loss: 0.511\n",
      "[1,273500] loss: 0.483\n",
      "[1,274000] loss: 0.504\n",
      "Train accuracy: tensor(72.5866, device='cuda:0')\n",
      "[1,274500] loss: 0.495\n",
      "[1,275000] loss: 0.500\n",
      "[1,275500] loss: 0.499\n",
      "[1,276000] loss: 0.502\n",
      "Train accuracy: tensor(74.0099, device='cuda:0')\n",
      "[1,276500] loss: 0.501\n",
      "[1,277000] loss: 0.489\n",
      "[1,277500] loss: 0.495\n",
      "[1,278000] loss: 0.496\n",
      "Train accuracy: tensor(73.7005, device='cuda:0')\n",
      "[1,278500] loss: 0.492\n",
      "[1,279000] loss: 0.494\n",
      "[1,279500] loss: 0.500\n",
      "[1,280000] loss: 0.498\n",
      "Train accuracy: tensor(73.2054, device='cuda:0')\n",
      "[1,280500] loss: 0.495\n",
      "[1,281000] loss: 0.504\n",
      "[1,281500] loss: 0.488\n",
      "[1,282000] loss: 0.496\n",
      "Train accuracy: tensor(73.8243, device='cuda:0')\n",
      "[1,282500] loss: 0.494\n",
      "[1,283000] loss: 0.500\n",
      "[1,283500] loss: 0.496\n",
      "[1,284000] loss: 0.491\n",
      "Train accuracy: tensor(73.2673, device='cuda:0')\n",
      "[1,284500] loss: 0.495\n",
      "[1,285000] loss: 0.493\n",
      "[1,285500] loss: 0.488\n",
      "[1,286000] loss: 0.506\n",
      "Train accuracy: tensor(76.5470, device='cuda:0')\n",
      "[1,286500] loss: 0.506\n",
      "[1,287000] loss: 0.495\n",
      "[1,287500] loss: 0.498\n",
      "[1,288000] loss: 0.490\n",
      "Train accuracy: tensor(74.7525, device='cuda:0')\n",
      "[1,288500] loss: 0.495\n",
      "[1,289000] loss: 0.494\n",
      "[1,289500] loss: 0.508\n",
      "[1,290000] loss: 0.495\n",
      "Train accuracy: tensor(74.3193, device='cuda:0')\n",
      "[1,290500] loss: 0.492\n",
      "[1,291000] loss: 0.492\n",
      "[1,291500] loss: 0.491\n",
      "[1,292000] loss: 0.491\n",
      "Train accuracy: tensor(75.1238, device='cuda:0')\n",
      "[1,292500] loss: 0.498\n",
      "[1,293000] loss: 0.505\n",
      "[1,293500] loss: 0.496\n",
      "[1,294000] loss: 0.499\n",
      "Train accuracy: tensor(74.2574, device='cuda:0')\n",
      "[1,294500] loss: 0.499\n",
      "[1,295000] loss: 0.499\n",
      "[1,295500] loss: 0.497\n",
      "[1,296000] loss: 0.502\n",
      "Train accuracy: tensor(75.2475, device='cuda:0')\n",
      "[1,296500] loss: 0.494\n",
      "[1,297000] loss: 0.492\n",
      "[1,297500] loss: 0.501\n",
      "[1,298000] loss: 0.504\n",
      "Train accuracy: tensor(74.6906, device='cuda:0')\n",
      "[1,298500] loss: 0.505\n",
      "[1,299000] loss: 0.492\n",
      "[1,299500] loss: 0.500\n",
      "[1,300000] loss: 0.502\n",
      "Train accuracy: tensor(74.3193, device='cuda:0')\n",
      "[1,300500] loss: 0.490\n",
      "[1,301000] loss: 0.500\n",
      "[1,301500] loss: 0.498\n",
      "[1,302000] loss: 0.502\n",
      "Train accuracy: tensor(75.3094, device='cuda:0')\n",
      "[1,302500] loss: 0.502\n",
      "[1,303000] loss: 0.498\n",
      "[1,303500] loss: 0.499\n",
      "[1,304000] loss: 0.500\n",
      "Train accuracy: tensor(75.2475, device='cuda:0')\n",
      "[1,304500] loss: 0.497\n",
      "[1,305000] loss: 0.506\n",
      "[1,305500] loss: 0.501\n",
      "[1,306000] loss: 0.506\n",
      "Train accuracy: tensor(74.5049, device='cuda:0')\n",
      "[1,306500] loss: 0.491\n",
      "[1,307000] loss: 0.500\n",
      "[1,307500] loss: 0.493\n",
      "[1,308000] loss: 0.499\n",
      "Train accuracy: tensor(72.5247, device='cuda:0')\n",
      "[1,308500] loss: 0.503\n",
      "[1,309000] loss: 0.490\n",
      "[1,309500] loss: 0.504\n",
      "[1,310000] loss: 0.501\n",
      "Train accuracy: tensor(74.9381, device='cuda:0')\n",
      "[1,310500] loss: 0.499\n",
      "[1,311000] loss: 0.501\n",
      "[1,311500] loss: 0.502\n",
      "[1,312000] loss: 0.500\n",
      "Train accuracy: tensor(74.2574, device='cuda:0')\n",
      "[1,312500] loss: 0.505\n",
      "[1,313000] loss: 0.495\n",
      "[1,313500] loss: 0.512\n",
      "[1,314000] loss: 0.494\n",
      "Train accuracy: tensor(72.7723, device='cuda:0')\n",
      "[1,314500] loss: 0.498\n",
      "[1,315000] loss: 0.500\n",
      "[1,315500] loss: 0.503\n",
      "[1,316000] loss: 0.499\n",
      "Train accuracy: tensor(74.6287, device='cuda:0')\n",
      "[1,316500] loss: 0.498\n",
      "[1,317000] loss: 0.492\n",
      "[1,317500] loss: 0.496\n",
      "[1,318000] loss: 0.511\n",
      "Train accuracy: tensor(75.3094, device='cuda:0')\n",
      "[1,318500] loss: 0.498\n",
      "[1,319000] loss: 0.496\n",
      "[1,319500] loss: 0.506\n",
      "[1,320000] loss: 0.507\n",
      "Train accuracy: tensor(73.9480, device='cuda:0')\n",
      "[1,320500] loss: 0.502\n",
      "[1,321000] loss: 0.497\n",
      "[1,321500] loss: 0.494\n",
      "[1,322000] loss: 0.498\n",
      "Train accuracy: tensor(75.5569, device='cuda:0')\n",
      "[1,322500] loss: 0.501\n",
      "[1,323000] loss: 0.493\n",
      "[1,323500] loss: 0.501\n",
      "[1,324000] loss: 0.497\n",
      "Train accuracy: tensor(73.3292, device='cuda:0')\n",
      "[1,324500] loss: 0.500\n",
      "[1,325000] loss: 0.508\n",
      "[1,325500] loss: 0.491\n",
      "[1,326000] loss: 0.488\n",
      "Train accuracy: tensor(75.4332, device='cuda:0')\n",
      "[1,326500] loss: 0.494\n",
      "[1,327000] loss: 0.505\n",
      "[1,327500] loss: 0.503\n",
      "[1,328000] loss: 0.496\n",
      "Train accuracy: tensor(74.8762, device='cuda:0')\n",
      "[1,328500] loss: 0.488\n",
      "[1,329000] loss: 0.498\n",
      "[1,329500] loss: 0.497\n",
      "[1,330000] loss: 0.503\n",
      "Train accuracy: tensor(74.8762, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = .00000001\n",
    "num_epochs = 10\n",
    "criterion3 = nn.CrossEntropyLoss()\n",
    "#optimizer3=optim.Adam(my_model.parameters(),lr=learning_rate)\n",
    "optimizer3 = optim.SGD(my_model.parameters(),lr=learning_rate,momentum=.9)\n",
    "num_epochs=15\n",
    "train(my_model,criterion3,optimizer3,num_epochs,trainloader)\n",
    "\n",
    "#check_accuracy(trainloader, my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "lasting-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(my_model.state_dict(), './Prototype2.0-Adam-SGD-1C5L0B-2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Test_Model().to(device)\n",
    "test_model.load_state_dict(torch.load('./Prototype1.0-Adam/SGD-2C3L0B-1.pth'))\n",
    "check_accuracy(trainloader, test_model, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddff75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''./Prototype2.0-Adam-SGD-1C5L0B-2.pth\n",
    "class Test_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test_Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(7,128, kernel_size=3,stride=1)\n",
    "        self.max = nn.MaxPool2d(2,2)\n",
    "        self.linear = nn.Sequential(nn.Linear(1152, 512), nn.ReLU(), nn.Linear(512,512), nn.ReLU(), nn.Linear(512,128),\n",
    "                                   nn.ReLU(), nn.Linear(128,64), nn.ReLU(), nn.Linear(64,2))\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.normal_(self.conv1.weight,0, 1e-7)\n",
    "        torch.nn.init.normal_(self.conv2.weight,0, 1e-7)\n",
    "        torch.nn.init.normal_(self.conv3.weight,0, 1e-7)\n",
    "        torch.nn.init.normal_(self.conv4.weight,0, 1e-6)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        print(x.shape)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chess_Enviorment",
   "language": "python",
   "name": "chess_enviorment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
